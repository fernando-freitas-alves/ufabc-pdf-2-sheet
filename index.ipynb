{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UFABC PDF to Spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the ```url``` and ```file_name``` string variables that contain the URL of the PDF file to be converted and the new files name, repectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://prograd.ufabc.edu.br/pdf/turmas_salas_docentes_sa_2018.1.pdf\"\n",
    "file_name = \"2018.1_SA\" # without extention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries needed to display files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import FileLink\n",
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the PDF file...\n",
      "--2018-02-18 13:54:57--  http://prograd.ufabc.edu.br/pdf/turmas_salas_docentes_sa_2018.1.pdf\n",
      "Resolving prograd.ufabc.edu.br (prograd.ufabc.edu.br)... 200.133.215.63\n",
      "Connecting to prograd.ufabc.edu.br (prograd.ufabc.edu.br)|200.133.215.63|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 689670 (674K) [application/pdf]\n",
      "Saving to: ‘2018.1_SA.pdf’\n",
      "\n",
      "2018.1_SA.pdf       100%[===================>] 673.51K   256KB/s    in 2.6s    \n",
      "\n",
      "2018-02-18 13:55:00 (256 KB/s) - ‘2018.1_SA.pdf’ saved [689670/689670]\n",
      "\n",
      "PDF file saved as:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='2018.1_SA.pdf' target='_blank'>2018.1_SA.pdf</a><br>"
      ],
      "text/plain": [
       "/home/jovyan/2018.1_SA.pdf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"2018.1_SA.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f8848453208>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_pdf = file_name + '.pdf'\n",
    "!wget $url -O $file_name_pdf\n",
    "file_pdf = FileLink(file_name_pdf)\n",
    "!echo PDF file saved as:\n",
    "display(file_pdf)\n",
    "IFrame(file_name_pdf, width=600, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PDF file is converted to a CSV file (*this might take a while*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_csv = file_name + \".csv\"\n",
    "!java -Dfile.encoding=utf-8 -jar tabula.jar -l --pages 3 $file_name_pdf -o $file_name_csv\n",
    "file_csv = FileLink(file_name_csv)\n",
    "!echo CSV file saved as:\n",
    "display(file_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure and simplify the Natural Language Toolkit (NTLK) Portuguese treebank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e807eecb99b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# nltk.download('punkt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# nltk.download('averaged_perceptron_tagger')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'floresta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('floresta')\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import floresta\n",
    "def simplify_tag(t):\n",
    "    if \"+\" in t:\n",
    "        return t[t.index(\"+\")+1:]\n",
    "    else:\n",
    "        return t\n",
    "twords = nltk.corpus.floresta.tagged_words()\n",
    "twords = [(w.lower(),simplify_tag(t)) for (w,t) in twords]\n",
    "\n",
    "# Insert some missing prepositions\n",
    "twords.insert(0,('da','prp'))\n",
    "twords.insert(0,('de','prp'))\n",
    "twords.insert(0,('di','prp'))\n",
    "twords.insert(0,('do','prp'))\n",
    "twords.insert(0,('du','prp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With NTLK propely prepared, create a ```title_pos_tag``` function that imitates ```title``` built-in function but doesn't capitalize conjunctions and prepositions. It is useful when titling proper names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_pos_tag(text):\n",
    "    def pos_tag_portuguese(tokens):\n",
    "        for index in range(len(tokens)):\n",
    "            for word in twords:\n",
    "                token = tokens[index].lower()\n",
    "                if word[0] == token:\n",
    "                    tag = word[1]\n",
    "                    tokens[index] = (token, tag)\n",
    "                    break\n",
    "        return tokens\n",
    "    tokens = tokenize.word_tokenize(text, language='portuguese')\n",
    "    tagged = pos_tag_portuguese(tokens)\n",
    "    new_text = ''\n",
    "    for index in range(len(tagged)):\n",
    "        token = tagged[index]\n",
    "        if isinstance(token, tuple):\n",
    "            word = token[0]\n",
    "            tag  = token[1]\n",
    "            # n:         substantivo\n",
    "            # prop:      nome próprio\n",
    "            # art:       artigo\n",
    "            # pron:      pronome\n",
    "            # pron-pers: pronome pessoal\n",
    "            # pron-det:  pronome determinativo\n",
    "            # pron-indp: substantivo/pron-indp\n",
    "            # adj:       adjetivo\n",
    "            # n-adj:     substantivo/adjetivo\n",
    "            # v:         verbo\n",
    "            # v-fin:     verbo finitivo\n",
    "            # v-inf:     verbo infinitivo\n",
    "            # v-pcp:     verbo particípio\n",
    "            # v-ger:     verbo gerúndio\n",
    "            # num:       numeral\n",
    "            # prp:       preposição\n",
    "            # adj:       adjetivo\n",
    "            # conj:      conjunção\n",
    "            # conj-s:    conjunção subordinativa\n",
    "            # conj-c:    conjunção coordenativa\n",
    "            # intj:      interjeição\n",
    "            # adv:       advérbio\n",
    "            # xxx:       outro\n",
    "            if 'conj' in tag or \\\n",
    "               'prp'  in tag:\n",
    "                new_text = new_text + ' ' + word.lower()\n",
    "            else:\n",
    "                new_text = new_text + ' ' + word.capitalize()\n",
    "        else:\n",
    "            new_text = new_text + ' ' + token.capitalize()\n",
    "    new_text = new_text.strip()\n",
    "#     return (new_text, tagged) # uncomment this line if is desired to retriev the tags as well\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an object that shows expandable JSON files (*credits to David Caldwell*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from IPython.display import HTML\n",
    "# from IPython.display import display_javascript, display_html#, display\n",
    "import json\n",
    "\n",
    "class RenderJSON(object):\n",
    "    def __init__(self, json_data):\n",
    "        if isinstance(json_data, dict):\n",
    "            self.json_str = json.dumps(json_data)\n",
    "        else:\n",
    "            self.json_str = json_data\n",
    "        self.uuid = str(uuid.uuid4())\n",
    "\n",
    "    def _ipython_display_(self):\n",
    "        htmlstr = \"\"\"\n",
    "        <html>\n",
    "            <head>\n",
    "                <style>body {background-color:yellow;}</style>\n",
    "            </head>\n",
    "            <body>\n",
    "                <div id=\"{0}\" style=\"height: 600px; width:100%;\"></div>\n",
    "                <script>\n",
    "                    require([\"renderjson.js\"], function() {\n",
    "                        document.getElementById('{0}').appendChild(renderjson({1}))\n",
    "                    });\n",
    "                </script>\n",
    "            </body>\n",
    "        </html>\n",
    "        \"\"\".format(self.uuid, self.json_str)\n",
    "        HTML(htmlstr)\n",
    "#         display_html('<div id=\"{}\" style=\"height: 600px; width:100%;\"></div>'.format(self.uuid), raw=True)\n",
    "#         display_javascript(\"\"\"\n",
    "#         require([\"renderjson.js\"], function() {\n",
    "#             document.getElementById('%s').appendChild(renderjson(%s))\n",
    "#         });\n",
    "#         \"\"\" % (self.uuid, self.json_str), raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CSV file is then processed into a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2018.1_SA.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0bae2364a657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mfull_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mweek_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'segunda'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'terça'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'quarta'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'quinta'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sexta'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sábado'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'domingo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2018.1_SA.csv'"
     ]
    }
   ],
   "source": [
    "file_name_json = file_name + '.json'\n",
    "import csv\n",
    "with open(file_name_csv, encoding=\"utf-8\") as csv_file:\n",
    "    full_data = []\n",
    "    content = csv.reader(csv_file, delimiter=',', quotechar='\"')\n",
    "    week_names = ('segunda','terça','quarta','quinta','sexta','sábado','domingo')\n",
    "    index = -1\n",
    "    for row in content:\n",
    "        index = index + 1\n",
    "        if index:\n",
    "#             print(', '.join(row).replace('\\r',''))\n",
    "#             print()\n",
    "            column = 0\n",
    "            for cell in row:\n",
    "                column = column + 1\n",
    "                data = cell.replace('\\r','').replace('\\n',' ').replace(' , ',', ').strip()\n",
    "                if   data == '¬': data = ''\n",
    "                elif data == '0': data = ''\n",
    "\n",
    "                # Código\n",
    "                if column == 1:\n",
    "                    codigo = data.upper()\n",
    "\n",
    "                # Disciplina - turma\n",
    "                elif column == 2:\n",
    "                    # Campus\n",
    "                    data, _, campus = data.rpartition('(')\n",
    "                    campus = title_pos_tag(campus[:-1])\n",
    "\n",
    "                    # Disciplina\n",
    "                    disciplina, _, data = data.strip().rpartition(' ')\n",
    "                    disciplina = title_pos_tag(disciplina)\n",
    "\n",
    "                    # Turma e período\n",
    "                    turma, _, periodo = data.strip().rpartition('-')\n",
    "                    turma   = turma.upper()\n",
    "                    periodo = periodo.capitalize()\n",
    "                    \n",
    "                    # Subcódigo\n",
    "                    subcodigo, _, _ = codigo.partition('-')\n",
    "                    subcodigo = subcodigo[len(turma)+1:]\n",
    "\n",
    "\n",
    "                # Teoria\n",
    "                elif column == 3:\n",
    "                    for week in week_names:\n",
    "                        data = data.replace(week, '\\n' + week)\n",
    "                    teoria = data.replace(', \\n','\\n').strip().splitlines()\n",
    "                    \n",
    "                    teoria_num_of_days = len(teoria)\n",
    "                    teoria_dia_da_semana = [None]*teoria_num_of_days\n",
    "                    teoria_entrada       = [None]*teoria_num_of_days\n",
    "                    teoria_saida         = [None]*teoria_num_of_days\n",
    "                    teoria_sala          = [None]*teoria_num_of_days\n",
    "                    teoria_frequencia    = [None]*teoria_num_of_days\n",
    "                    for day in range(teoria_num_of_days):\n",
    "                        data = teoria[day]\n",
    "                        teoria_dia_da_semana[day], _, data                   = data.partition(' das ')\n",
    "                        teoria_entrada[day],       _, data                   = data.partition(' às ')\n",
    "                        teoria_saida[day],         _, data                   = data.partition(', sala ')\n",
    "                        teoria_sala[day],          _, teoria_frequencia[day] = data.partition(', ')\n",
    "                        \n",
    "                        teoria_dia_da_semana[day] = teoria_dia_da_semana[day].capitalize()\n",
    "                        teoria_frequencia[day]    = teoria_frequencia[day].capitalize()\n",
    "                        teoria_sala[day]          = teoria_sala[day].upper()\n",
    "\n",
    "                # Prática\n",
    "                elif column == 4:\n",
    "                    for week in week_names:\n",
    "                        data = data.replace(week, '\\n' + week)\n",
    "                    pratica = data.replace(',\\n','\\n').strip().splitlines()\n",
    "                    \n",
    "                    pratica_num_of_days = len(pratica)\n",
    "                    pratica_dia_da_semana = [None]*pratica_num_of_days\n",
    "                    pratica_entrada       = [None]*pratica_num_of_days\n",
    "                    pratica_saida         = [None]*pratica_num_of_days\n",
    "                    pratica_sala          = [None]*pratica_num_of_days\n",
    "                    pratica_frequencia    = [None]*pratica_num_of_days\n",
    "                    for day in range(pratica_num_of_days):\n",
    "                        data = pratica[day]\n",
    "                        pratica_dia_da_semana[day], _, data                   = data.partition(' das ')\n",
    "                        pratica_entrada[day],       _, data                   = data.partition(' às ')\n",
    "                        pratica_saida[day],         _, data                   = data.partition(', sala ')\n",
    "                        pratica_sala[day],          _, pratica_frequencia[day] = data.partition(', ')\n",
    "                        \n",
    "                        pratica_dia_da_semana[day] = pratica_dia_da_semana[day].capitalize()\n",
    "                        pratica_frequencia[day]    = pratica_frequencia[day].capitalize()\n",
    "                        pratica_sala[day]          = pratica_sala[day].upper()\n",
    "\n",
    "                # Docente teoria\n",
    "                elif column == 5:\n",
    "                    docente_teoria = title_pos_tag(data)\n",
    "\n",
    "                # Docente prática\n",
    "                elif column == 6:\n",
    "                    docente_pratica = title_pos_tag(data)\n",
    "\n",
    "            teoria = []\n",
    "            i = 0\n",
    "            for day in range(teoria_num_of_days):\n",
    "                i = i + 1\n",
    "                teoria_new = {'id': i,\n",
    "                              'dia_da_semana': teoria_dia_da_semana[day],\n",
    "                              'horario_de_entrada': teoria_entrada[day],\n",
    "                              'horario_de_saida': teoria_saida[day],\n",
    "                              'sala': teoria_sala[day],\n",
    "                              'frequencia': teoria_frequencia[day]}\n",
    "                teoria.append(teoria_new)\n",
    "                \n",
    "            pratica = []\n",
    "            i = -1\n",
    "            for day in range(pratica_num_of_days):\n",
    "                i = i + 1\n",
    "                pratica_new = {'id': i,\n",
    "                               'dia_da_semana': pratica_dia_da_semana[day],\n",
    "                               'horario_de_entrada': pratica_entrada[day],\n",
    "                               'horario_de_saida': pratica_saida[day],\n",
    "                               'sala': pratica_sala[day],\n",
    "                               'frequencia': pratica_frequencia[day]}\n",
    "                pratica.append(pratica_new)\n",
    "                \n",
    "            new_data = {'id': index-1,\n",
    "                        'codigo': codigo,\n",
    "                        'subcodigo': subcodigo,\n",
    "                        'disciplina': disciplina,\n",
    "                        'campus': campus,\n",
    "                        'periodo': periodo,\n",
    "                        'turma': turma,\n",
    "                        'teoria': teoria,\n",
    "                        'pratica': pratica,\n",
    "                        'docente_teoria': docente_teoria,\n",
    "                        'docente_pratica': docente_pratica}\n",
    "            full_data.append(new_data)\n",
    "    with open(file_name_json, 'w') as file:\n",
    "        json.dump(full_data, file)\n",
    "        file_json = FileLink(file_name_json)\n",
    "        !echo JSON file saved as:\n",
    "        display(file_json)\n",
    "    with open(file_name_json, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        RenderJSON(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"3f165a98-e44b-4145-a2a7-e9b21bc0df2d\" style=\"height: 600px; width:100%;\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        require([\"https://rawgit.com/caldwell/renderjson/master/renderjson.js\"], function() {\n",
       "        document.getElementById('3f165a98-e44b-4145-a2a7-e9b21bc0df2d').appendChild(renderjson([{'id': 0, 'codigo': 'DAESZM035-17SA', 'subcodigo': 'ESZM035', 'disciplina': 'Aditivação de Polímeros', 'campus': 'Santo André', 'periodo': 'Diurno', 'turma': 'A', 'teoria': [{'id': 1, 'dia_da_semana': 'Segunda', 'horario_de_entrada': '10:00', 'horario_de_saida': '12:00', 'sala': 'S-301-3', 'frequencia': 'Semanal'}, {'id': 2, 'dia_da_semana': 'Quinta', 'horario_de_entrada': '08:00', 'horario_de_saida': '10:00', 'sala': 'S-301-3', 'frequencia': 'Semanal'}], 'pratica': [], 'docente_teoria': 'Anne Cristine Chinellato', 'docente_pratica': ''}, {'id': 1, 'codigo': 'NA1MCTB001-17SA', 'subcodigo': 'MCTB001', 'disciplina': 'Álgebra Linear', 'campus': 'Santo André', 'periodo': 'Noturno', 'turma': 'A1', 'teoria': [{'id': 1, 'dia_da_semana': 'Segunda', 'horario_de_entrada': '19:00', 'horario_de_saida': '21:00', 'sala': 'S-204-0', 'frequencia': 'Semanal'}, {'id': 2, 'dia_da_semana': 'Quarta', 'horario_de_entrada': '21:00', 'horario_de_saida': '23:00', 'sala': 'S-204-0', 'frequencia': 'Semanal'}, {'id': 3, 'dia_da_semana': 'Sexta', 'horario_de_entrada': '19:00', 'horario_de_saida': '21:00', 'sala': 'A-108-0', 'frequencia': 'Semanal'}], 'pratica': [], 'docente_teoria': 'Roldão da Rocha Junior', 'docente_pratica': ''}, {'id': 2, 'codigo': 'DAMCTB001-17SA', 'subcodigo': 'MCTB001', 'disciplina': 'Álgebra Linear', 'campus': 'Santo André', 'periodo': 'Diurno', 'turma': 'A', 'teoria': [{'id': 1, 'dia_da_semana': 'Segunda', 'horario_de_entrada': '08:00', 'horario_de_saida': '10:00', 'sala': 'A-108-0', 'frequencia': 'Semanal'}, {'id': 2, 'dia_da_semana': 'Quarta', 'horario_de_entrada': '10:00', 'horario_de_saida': '12:00', 'sala': 'A-108-0', 'frequencia': 'Semanal'}, {'id': 3, 'dia_da_semana': 'Sexta', 'horario_de_entrada': '08:00', 'horario_de_saida': '10:00', 'sala': 'A-108-0', 'frequencia': 'Semanal'}], 'pratica': [], 'docente_teoria': 'Rodrigo Roque Dias', 'docente_pratica': ''}, {'id': 3, 'codigo': 'NAMCTB001-17SA', 'subcodigo': 'MCTB001', 'disciplina': 'Álgebra Linear', 'campus': 'Santo André', 'periodo': 'Noturno', 'turma': 'A', 'teoria': [{'id': 1, 'dia_da_semana': 'Segunda', 'horario_de_entrada': '19:00', 'horario_de_saida': '21:00', 'sala': 'S-212-0', 'frequencia': 'Semanal'}, {'id': 2, 'dia_da_semana': 'Quarta', 'horario_de_entrada': '21:00', 'horario_de_saida': '23:00', 'sala': 'S-212-0', 'frequencia': 'Semanal'}, {'id': 3, 'dia_da_semana': 'Sexta', 'horario_de_entrada': '19:00', 'horario_de_saida': '21:00', 'sala': 'S-212-0', 'frequencia': 'Semanal'}], 'pratica': [], 'docente_teoria': 'Dmitry Vasilevich', 'docente_pratica': ''}, {'id': 4, 'codigo': 'DA1MCTA001-17SA', 'subcodigo': 'MCTA001', 'disciplina': 'Algoritmos e Estruturas de Dados I', 'campus': 'Santo André', 'periodo': 'Diurno', 'turma': 'A1', 'teoria': [{'id': 1, 'dia_da_semana': 'Quarta', 'horario_de_entrada': '08:00', 'horario_de_saida': '10:00', 'sala': 'S-301-1', 'frequencia': 'Semanal'}], 'pratica': [{'id': 0, 'dia_da_semana': 'Segunda', 'horario_de_entrada': '10:00', 'horario_de_saida': '12:00', 'sala': '407-2', 'frequencia': 'Semanal'}], 'docente_teoria': 'Mirtha Lina Fernandez Venero', 'docente_pratica': 'Mirtha Lina Fernandez Venero'}, {'id': 5, 'codigo': 'NA1MCTA001-17SA', 'subcodigo': 'MCTA001', 'disciplina': 'Algoritmos e Estruturas de Dados I', 'campus': 'Santo André', 'periodo': 'Noturno', 'turma': 'A1', 'teoria': [{'id': 1, 'dia_da_semana': 'Quarta', 'horario_de_entrada': '19:00', 'horario_de_saida': '21:00', 'sala': 'S-301-1', 'frequencia': 'Semanal'}], 'pratica': [{'id': 0, 'dia_da_semana': 'Segunda', 'horario_de_entrada': '21:00', 'horario_de_saida': '23:00', 'sala': '402-2', 'frequencia': 'Semanal'}], 'docente_teoria': 'Cristiane Maria Sato', 'docente_pratica': 'Cristiane Maria Sato'}, {'id': 6, 'codigo': 'DA2MCTA001-17SA', 'subcodigo': 'MCTA001', 'disciplina': 'Algoritmos e Estruturas de Dados I', 'campus': 'Santo André', 'periodo': 'Diurno', 'turma': 'A2', 'teoria': [{'id': 1, 'dia_da_semana': 'Quarta', 'horario_de_entrada': '08:00', 'horario_de_saida': '10:00', 'sala': 'S-301-1', 'frequencia': 'Semanal'}], 'pratica': [{'id': 0, 'dia_da_semana': 'Segunda', 'horario_de_entrada': '10:00', 'horario_de_saida': '12:00', 'sala': '409-2', 'frequencia': 'Semanal'}], 'docente_teoria': 'Mirtha Lina Fernandez Venero', 'docente_pratica': 'Paulo Henrique Pisani'}, {'id': 7, 'codigo': 'NA2MCTA001-17SA', 'subcodigo': 'MCTA001', 'disciplina': 'Algoritmos e Estruturas de Dados I', 'campus': 'Santo André', 'periodo': 'Noturno', 'turma': 'A2', 'teoria': [{'id': 1, 'dia_da_semana': 'Quarta', 'horario_de_entrada': '19:00', 'horario_de_saida': '21:00', 'sala': 'S-301-1', 'frequencia': 'Semanal'}], 'pratica': [{'id': 0, 'dia_da_semana': 'Segunda', 'horario_de_entrada': '21:00', 'horario_de_saida': '23:00', 'sala': '404-2', 'frequencia': 'Semanal'}], 'docente_teoria': 'Cristiane Maria Sato', 'docente_pratica': 'Daniel Morgato Martin'}, {'id': 8, 'codigo': 'DB1MCTA001-17SA', 'subcodigo': 'MCTA001', 'disciplina': 'Algoritmos e Estruturas de Dados I', 'campus': 'Santo André', 'periodo': 'Diurno', 'turma': 'B1', 'teoria': [{'id': 1, 'dia_da_semana': 'Segunda', 'horario_de_entrada': '16:00', 'horario_de_saida': '18:00', 'sala': 'A-106-0', 'frequencia': 'Semanal'}], 'pratica': [{'id': 0, 'dia_da_semana': 'Quarta', 'horario_de_entrada': '16:00', 'horario_de_saida': '18:00', 'sala': '409-2', 'frequencia': 'Semanal'}], 'docente_teoria': 'Monael Pinheiro Ribeiro', 'docente_pratica': 'Monael Pinheiro Ribeiro'}, {'id': 9, 'codigo': 'DB2MCTA001-17SA', 'subcodigo': 'MCTA001', 'disciplina': 'Algoritmos e Estruturas de Dados I', 'campus': 'Santo André', 'periodo': 'Diurno', 'turma': 'B2', 'teoria': [{'id': 1, 'dia_da_semana': 'Segunda', 'horario_de_entrada': '16:00', 'horario_de_saida': '18:00', 'sala': 'A-106-0', 'frequencia': 'Semanal'}], 'pratica': [{'id': 0, 'dia_da_semana': 'Quarta', 'horario_de_entrada': '16:00', 'horario_de_saida': '18:00', 'sala': '407-2', 'frequencia': 'Semanal'}], 'docente_teoria': 'Monael Pinheiro Ribeiro', 'docente_pratica': 'Paulo Henrique Pisani'}, {'id': 10, 'codigo': 'DAMCZA035-14SA', 'subcodigo': 'MCZA035', 'disciplina': 'Algoritmos Probabilísticos', 'campus': 'Santo André', 'periodo': 'Diurno', 'turma': 'A', 'teoria': [{'id': 1, 'dia_da_semana': 'Quarta', 'horario_de_entrada': '10:00', 'horario_de_saida': '12:00', 'sala': 'S-301-2', 'frequencia': 'Semanal'}, {'id': 2, 'dia_da_semana': 'Sexta', 'horario_de_entrada': '08:00', 'horario_de_saida': '10:00', 'sala': 'S-301-2', 'frequencia': 'Semanal'}], 'pratica': [], 'docente_teoria': 'Jair Donadelli Junior', 'docente_pratica': ''}]))\n",
       "        });\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the JSON file into a spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAESZM035-17SA\n",
      "NA1MCTB001-17SA\n",
      "DAMCTB001-17SA\n",
      "NAMCTB001-17SA\n",
      "DA1MCTA001-17SA\n",
      "NA1MCTA001-17SA\n",
      "DA2MCTA001-17SA\n",
      "NA2MCTA001-17SA\n",
      "DB1MCTA001-17SA\n",
      "DB2MCTA001-17SA\n",
      "DAMCZA035-14SA\n"
     ]
    }
   ],
   "source": [
    "with open(file_name_json, 'r') as file:\n",
    "    data = json.load(file)\n",
    "#     print(data[0]['codigo'])\n",
    "    for disciplina in data:\n",
    "        print(disciplina['codigo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fa2d5124e840cdb57b2a4a2570f3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>QgridWidget</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defaultColumnWidth': 150, 'rowHeight': 28, 'enableColumnReorder': False, 'enableTextSelectionOnCells': True, 'editable': True, 'autoEdit': False, 'explicitInitialization': True, 'maxVisibleRows': 15, 'minVisibleRows': 8}, precision=5, show_toolbar=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import qgrid\n",
    "randn = np.random.randn\n",
    "df_types = pd.DataFrame({\n",
    "    'A' : pd.Series(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n",
    "               '2013-01-05', '2013-01-06', '2013-01-07', '2013-01-08', '2013-01-09'],index=list(range(9)),dtype='datetime64[ns]'),\n",
    "    'B' : pd.Series(randn(9),index=list(range(9)),dtype='float32'),\n",
    "    'C' : pd.Categorical([\"washington\", \"adams\", \"washington\", \"madison\", \"lincoln\",\"jefferson\", \"hamilton\", \"roosevelt\", \"kennedy\"]),\n",
    "    'D' : [\"foo\", \"bar\", \"buzz\", \"bippity\",\"boppity\", \"foo\", \"foo\", \"bar\", \"zoo\"] })\n",
    "df_types['E'] = df_types['D'] == 'foo'\n",
    "qgrid_widget = qgrid.QgridWidget(df=df_types, show_toolbar=True)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
